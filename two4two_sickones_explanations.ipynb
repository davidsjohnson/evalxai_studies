{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "e2fupDHq8Cye"
      ],
      "toc_visible": true,
      "mount_file_id": "1Ws9hgMF2dk4jB0t5F5ox6Kj2eCDCHTws",
      "authorship_tag": "ABX9TyN5tJrk2UFMquiEiDitiU2m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidsjohnson/evalxai_studies/blob/main/two4two_sickones_explanations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yi0pAex6RNDU"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from skimage.transform import resize\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Params"
      ],
      "metadata": {
        "id": "rxTk1ctGpvnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoints = True\n",
        "\n",
        "modeltype = 'mobilenet'\n",
        "\n",
        "biased_ds = 'sick_ones_bendcolorbias'\n",
        "nobias_ds = 'sick_ones_bendbias'\n",
        "\n",
        "epochs = 10\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "SLpJb-H9pxs_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Load Datasets"
      ],
      "metadata": {
        "id": "Ua-n5ADsde6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataframe(data_dir, dataset):\n",
        "  data_dir = data_dir / dataset\n",
        "  df = pd.read_json(data_dir / 'parameters.jsonl', lines=True)\n",
        "  df['filename'] = df['id'] + '.png'\n",
        "  df['ill'] = df['ill'].astype(int).astype(str)\n",
        "  return df\n",
        "\n",
        "def load_data_gens(trainval_datadir, test_datadir):\n",
        "  train_df = load_dataframe(trainval_datadir, 'train')\n",
        "  valid_df = load_dataframe(trainval_datadir, 'validation')\n",
        "  test_df = load_dataframe(test_datadir, 'test')\n",
        "\n",
        "  datagen = ImageDataGenerator(rescale=1./255)\n",
        "  train_generator = datagen.flow_from_dataframe(dataframe=train_df, directory=trainval_datadir / 'train', target_size=(128, 128),\n",
        "                                                x_col='filename', y_col='ill', batch_size=64, shuffle=True)\n",
        "  valid_generator = datagen.flow_from_dataframe(dataframe=valid_df, directory=trainval_datadir / 'validation', target_size=(128, 128),\n",
        "                                                x_col='filename', y_col='ill', batch_size=64, shuffle=False)\n",
        "  test_generator = datagen.flow_from_dataframe(dataframe=test_df, directory=test_datadir / 'test',  target_size=(128, 128),\n",
        "                                               x_col='filename', y_col='ill',\n",
        "                                               batch_size=64, shuffle=False)\n",
        "\n",
        "  return train_generator, valid_generator, test_generator"
      ],
      "metadata": {
        "id": "TzbAMnMyeEru"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive = Path('/content/drive/MyDrive')\n",
        "relative_model_path = \"two4two_sickones_models\"\n",
        "base_path = gdrive / relative_model_path\n",
        "\n",
        "output = gdrive / 'hcxai' / 'blocky_diagnosis'\n",
        "\n",
        "base_path"
      ],
      "metadata": {
        "id": "eSBMiJ-ARVcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c54773-6094-451c-af0a-62f64c433754"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/two4two_sickones_models')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_sickones = keras.utils.get_file(\n",
        "    origin = \"https://uni-bielefeld.sciebo.de/s/Ve8WuZv3teRtVhG/download\",\n",
        "    fname = 'two4two_datasets.tar.gz',\n",
        "    extract = True,\n",
        "    archive_format = 'tar'\n",
        ")\n",
        "data_dir_sickones = Path(data_dir_sickones)"
      ],
      "metadata": {
        "id": "HPi0wvbicrct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6538db-b47f-4f36-a70c-a890b5442457"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://uni-bielefeld.sciebo.de/s/Ve8WuZv3teRtVhG/download\n",
            "3837766635/3837766635 [==============================] - 245s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Biased and Unbiased datasets"
      ],
      "metadata": {
        "id": "ReNR_Y0QProQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nobias_dir = data_dir_sickones.with_suffix('').with_suffix('') / nobias_ds\n",
        "biased_dir = data_dir_sickones.with_suffix('').with_suffix('') / biased_ds\n",
        "\n",
        "nobias_dir, biased_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn3D8znPQN-F",
        "outputId": "d8be8aeb-64e9-4172-a269-49de0351db5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/root/.keras/datasets/two4two_datasets/sick_ones_bendbias'),\n",
              " PosixPath('/root/.keras/datasets/two4two_datasets/sick_ones_bendcolorbias'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nobias_model_path = base_path / nobias_ds / f'{modeltype}'\n",
        "biased_model_path = base_path / biased_ds / f'{modeltype}'\n",
        "\n",
        "nobias_model_path, biased_model_path"
      ],
      "metadata": {
        "id": "msUfBSYCRzNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01e7869-6a0b-48cb-ea43-c019091c89fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/content/drive/MyDrive/two4two_sickones_models/sick_ones_bendbias/mobilenet'),\n",
              " PosixPath('/content/drive/MyDrive/two4two_sickones_models/sick_ones_bendcolorbias/mobilenet'))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nobias_model_exists = os.path.exists(nobias_model_path)\n",
        "biased_model_exists = os.path.exists(biased_model_path)\n",
        "\n",
        "nobias_model_exists, biased_model_exists"
      ],
      "metadata": {
        "id": "C5qJhHWOS3av",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115445de-6201-435e-87f9-e99b6501b8fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataframes\n",
        "nobias_train_df,  nobias_valid_df, nobias_test_df = (load_dataframe(nobias_dir, 'train'),\n",
        "                                                     load_dataframe(nobias_dir, 'validation'),\n",
        "                                                     load_dataframe(nobias_dir, 'test'))\n",
        "nobias_train_df['sphere_diff'] = np.abs(nobias_train_df['spherical'] - nobias_train_df['ill_spherical'])\n",
        "nobias_valid_df['sphere_diff'] = np.abs(nobias_valid_df['spherical'] - nobias_valid_df['ill_spherical'])\n",
        "nobias_test_df['sphere_diff'] = np.abs(nobias_test_df['spherical'] - nobias_test_df['ill_spherical'])\n",
        "\n",
        "biased_train_df,  biased_valid_df, biased_test_df = (load_dataframe(biased_dir, 'train'),\n",
        "                                                     load_dataframe(biased_dir, 'validation'),\n",
        "                                                     load_dataframe(biased_dir, 'test'))\n",
        "biased_train_df['sphere_diff'] = np.abs(biased_train_df['spherical'] - biased_train_df['ill_spherical'])\n",
        "biased_valid_df['sphere_diff'] = np.abs(biased_valid_df['spherical'] - biased_valid_df['ill_spherical'])\n",
        "biased_test_df['sphere_diff'] = np.abs(biased_test_df['spherical'] - biased_test_df['ill_spherical'])"
      ],
      "metadata": {
        "id": "uODOD8uidxxU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data Gens\n",
        "nobias_train_gen, nobias_valid_gen, nobias_test_gen = load_data_gens(nobias_dir, nobias_dir)\n",
        "biased_train_gen, biased_valid_gen, biased_test_gen = load_data_gens(biased_dir, biased_dir)"
      ],
      "metadata": {
        "id": "Ttr_NsZDgPn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949f8799-3457-480c-c3d5-5e72f7934211"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80000 validated image filenames belonging to 2 classes.\n",
            "Found 1000 validated image filenames belonging to 2 classes.\n",
            "Found 3000 validated image filenames belonging to 2 classes.\n",
            "Found 80000 validated image filenames belonging to 2 classes.\n",
            "Found 1000 validated image filenames belonging to 2 classes.\n",
            "Found 3000 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Loading and Evaluation"
      ],
      "metadata": {
        "id": "AiMdu2w_dj2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(load_checkpoint: bool, model_filepath: Path, learning_rate: float):\n",
        "\n",
        "  if load_checkpoint:\n",
        "    model = keras.models.load_model(model_filepath)\n",
        "    print(f'loading existing checkpoint for mobilenet - {model_filepath}')\n",
        "  else:\n",
        "    print('Model does not exist or checkpoint not set to be loaded. Loading new mobilenet.')\n",
        "    base_model = keras.applications.MobileNetV2(\n",
        "        input_shape=(128, 128, 3),\n",
        "        alpha=1.0,\n",
        "        include_top=False,\n",
        "        weights=None,\n",
        "        input_tensor=None,\n",
        "        pooling='avg'\n",
        "    )\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        base_model,\n",
        "        layers.Dense(2, activation=\"softmax\"),\n",
        "    ])\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "  return model\n",
        "\n",
        "def get_simple_model(load_checkpoint: bool, model_filepath: Path, learning_rate: float):\n",
        "\n",
        "\n",
        "  if load_checkpoint:\n",
        "    model = keras.models.load_model(model_filepath)\n",
        "    print(f'loading existing checkpoint for simple net- {model_filepath}')\n",
        "  else:\n",
        "    print('Model does not exist or checkpoint not set to be loaded. Loading new simple net.')\n",
        "    model = keras.models.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(2, activation=\"softmax\"),\n",
        "    ])\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Lj_JL19gUabX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, test_generator):\n",
        "\n",
        "  print(f'Evaluating model on test data')\n",
        "  return model.evaluate(test_generator)[1]"
      ],
      "metadata": {
        "id": "p6S4wQb_XpYp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "GnDzvYfKdScq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Bias Model"
      ],
      "metadata": {
        "id": "0xTK5UD3WYVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if modeltype == 'mobilenet':\n",
        "  nobias_model = get_model(load_checkpoint=True,\n",
        "                           model_filepath=nobias_model_path,\n",
        "                           learning_rate=learning_rate)\n",
        "elif modeltype == 'simple':\n",
        "  nobias_model = get_simple_model(load_checkpoint=True,\n",
        "                                  model_filepath=nobias_model_path,\n",
        "                                  learning_rate=learning_rate)\n",
        "else:\n",
        "  print('Model type does not exist')\n",
        "  nobias_model = None"
      ],
      "metadata": {
        "id": "OdTfSs2XgJNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ebe744-cedc-45e9-c5d2-33618c65c54c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading existing checkpoint for mobilenet - /content/drive/MyDrive/two4two_sickones_models/sick_ones_bendbias/mobilenet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nobias_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEYrq1B1ZrPw",
        "outputId": "04e9f19f-6dcd-4f56-a605-27b2bdbe8477"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_128 (Func  (None, 1280)              2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2260546 (8.62 MB)\n",
            "Trainable params: 2226434 (8.49 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Biased Model"
      ],
      "metadata": {
        "id": "s_QTZllTWw8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if modeltype == 'mobilenet':\n",
        "  biased_model = get_model(load_checkpoint=True,\n",
        "                           model_filepath=biased_model_path,\n",
        "                           learning_rate=learning_rate)\n",
        "elif modeltype == 'simple':\n",
        "  biased_model = get_simple_model(load_checkpoint=True,\n",
        "                                  model_filepath=biased_model_path,\n",
        "                                  learning_rate=learning_rate)\n",
        "else:\n",
        "  print('Model type does not exist')\n",
        "  biased_model = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTItBeS_W0lF",
        "outputId": "ef2505c4-d8fa-4182-dd50-ada9e9aec87c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading existing checkpoint for mobilenet - /content/drive/MyDrive/two4two_sickones_models/sick_ones_bendcolorbias/mobilenet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biased_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9pNKME8W-YM",
        "outputId": "ebad2100-758b-49d7-c18a-15b6a979151a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_128 (Func  (None, 1280)              2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2260546 (8.62 MB)\n",
            "Trainable params: 2226434 (8.49 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval  Model"
      ],
      "metadata": {
        "id": "m3ezID58WQIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Bias Model"
      ],
      "metadata": {
        "id": "BJhM-E5SXxOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# results on nobias test\n",
        "acc = eval(nobias_model, nobias_test_gen)\n",
        "print(f'ACC: {acc}')\n",
        "probs = nobias_model.predict(nobias_test_gen)\n",
        "preds = np.argmax(probs, axis=-1)\n",
        "\n",
        "nobias_test_df['nobias_pred'] = preds\n",
        "nobias_test_df['nobias_pred'] = nobias_test_df['nobias_pred'].astype(str)\n",
        "(nobias_test_df['nobias_pred'] == nobias_test_df['ill']).astype(int).mean()"
      ],
      "metadata": {
        "id": "lj2I88s0d4gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fd03c4-f1c6-4937-bc11-319f96965187"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on test data\n",
            "47/47 [==============================] - 13s 249ms/step - loss: 0.4659 - accuracy: 0.8113\n",
            "ACC: 0.8113333582878113\n",
            "47/47 [==============================] - 13s 248ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8113333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results on biased test\n",
        "acc = eval(nobias_model, biased_test_gen)\n",
        "print(f'ACC: {acc}')\n",
        "probs = nobias_model.predict(biased_test_gen)\n",
        "preds = np.argmax(probs, axis=-1)\n",
        "\n",
        "biased_test_df['nobias_pred'] = preds\n",
        "biased_test_df['nobias_pred'] = biased_test_df['nobias_pred'].astype(str)\n",
        "(biased_test_df['nobias_pred'] == biased_test_df['ill']).astype(int).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZI14flluOGX",
        "outputId": "b2a946cd-c00f-4ba5-e97f-26008d6aafe9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on test data\n",
            "47/47 [==============================] - 12s 249ms/step - loss: 0.4965 - accuracy: 0.7903\n",
            "ACC: 0.7903333306312561\n",
            "47/47 [==============================] - 12s 248ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7903333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Biased Model"
      ],
      "metadata": {
        "id": "hXqESqmEX7vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# results on nobias test\n",
        "acc = eval(biased_model, nobias_test_gen)\n",
        "print(f'ACC: {acc}')\n",
        "probs = biased_model.predict(nobias_test_gen)\n",
        "preds = np.argmax(probs, axis=-1)\n",
        "\n",
        "nobias_test_df['biased_pred'] = preds\n",
        "nobias_test_df['biased_pred'] = nobias_test_df['biased_pred'].astype(str)\n",
        "(nobias_test_df['biased_pred'] == nobias_test_df['ill']).astype(int).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6Kb0EcQbPOH",
        "outputId": "51c18d6f-1bd1-4704-d8a1-900ae53683ca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on test data\n",
            "47/47 [==============================] - 13s 257ms/step - loss: 0.5248 - accuracy: 0.7883\n",
            "ACC: 0.7883333563804626\n",
            "47/47 [==============================] - 13s 245ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7883333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results on biased test\n",
        "acc = eval(biased_model, biased_test_gen)\n",
        "print(f'ACC: {acc}')\n",
        "probs = biased_model.predict(biased_test_gen)\n",
        "preds = np.argmax(probs, axis=-1)\n",
        "\n",
        "biased_test_df['biased_pred'] = preds\n",
        "biased_test_df['biased_pred'] = biased_test_df['biased_pred'].astype(str)\n",
        "(biased_test_df['biased_pred'] == biased_test_df['ill']).astype(int).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiEPxBkXX7GZ",
        "outputId": "ce003a37-0155-42fa-ad37-6cec81130d63"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on test data\n",
            "47/47 [==============================] - 13s 266ms/step - loss: 0.4196 - accuracy: 0.8243\n",
            "ACC: 0.8243333101272583\n",
            "47/47 [==============================] - 13s 266ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8243333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanations"
      ],
      "metadata": {
        "id": "J2QsD51Yfm2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Explanation Dataset\n",
        "\n",
        "Select 20 images to represent challenging decision making tasks but where there is a clear final decision.\n",
        "\n",
        "(for now from nobias dataset with biased model predictions)\n",
        "\n",
        "- 16 - Correct predictions\n",
        "- 4 - Incorrect predictions\n",
        "\n",
        "represents accuracy of model (around $80\\%$)\n",
        "\n",
        "(actually I think this does not matter.  a small sample of 20 samples will be the same as teh original model, especially in hard cases.\n",
        "\n",
        "Will instead pick 6 total from each category\n",
        "\n",
        "- Correct Predictions (3 each Correct and 3 Incorrect)\n",
        "  - medhigh sphere diff and lowmed bend (**overlap** - ill and notill)\n",
        "  - lowmed sphere diff but medhigh bend (**overlap** - ill and notill)\n",
        "  - medhigh sphere diff and medhigh bend (**easy** - ill)\n",
        "  - lowmed sphere diff and lowmed bend (**easy** - ill)\n",
        "  - lowmed sphere diff but (1,3) changed pieces (**slightly difficult** - does XAI help show ambiguous pieces)\n"
      ],
      "metadata": {
        "id": "GI4A4VOXi7ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(df, n_rows, n_cols, img_dir, title, random_state=0):\n",
        "  \"\"\" Function to display images in a grid randomly selected from a dataframe of images.\n",
        "\n",
        "  Args:\n",
        "    df (pd.DataFrame): dataframe of images\n",
        "    n_rows (int): number of rows in the grid\n",
        "    n_cols (int): number of columns in the grid\n",
        "    title (str): title of the plot\n",
        "    random_state (int): random state for reproducibility\n",
        "  \"\"\"\n",
        "\n",
        "  if n_rows == 0 and n_cols == 0:\n",
        "    print(f'Not data to display for Figure - {title}')\n",
        "    return\n",
        "\n",
        "  if n_rows * n_cols < len(df):\n",
        "    df = df.sample(n_rows * n_cols, random_state=random_state)\n",
        "\n",
        "  figsize = (n_cols * 2, n_rows*2.5)\n",
        "  print(figsize)\n",
        "\n",
        "  test_images = np.array([Image.open(p).convert('RGB') for p in img_dir / df['filename']]) * 1. / 255\n",
        "  fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
        "  axes = np.array(axes)\n",
        "  for i, (ax, idx) in enumerate(zip(axes.flat, df.index)):\n",
        "    ax.imshow(test_images[i])\n",
        "    ax.set_title(f'Img Idx {idx}')\n",
        "    ax.axis('off')\n",
        "\n",
        "  fig.suptitle(title)\n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "BUjjk779crq5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correct Samples Selection\n"
      ],
      "metadata": {
        "id": "0UZ8CuXOZxal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup conditions\n",
        "def get_xai_conds(df, ill=False):\n",
        "\n",
        "  \"\"\"\n",
        "    - medhigh sphere diff and lowmed bend (**overlap** - ill and notill)\n",
        "    - lowmed sphere diff but medhigh bend (**overlap** - ill and notill)\n",
        "    - medhigh sphere diff and medhigh bend (**easy** - ill)\n",
        "    - lowmed sphere diff and lowmed bend (**easy** - notill)\n",
        "    - lowmed sphere diff but (1,3) changed pieces (**slightly difficult** - does XAI help show ambiguous pieces)\n",
        "  \"\"\"\n",
        "\n",
        "  medhigh_bend = (abs(df['bending']).quantile(0.50), abs(df['bending']).quantile(0.70))\n",
        "  medhigh_diff = (abs(df['sphere_diff']).quantile(0.50), abs(df['sphere_diff']).quantile(0.70))\n",
        "\n",
        "  lowmed_bend = (abs(df['bending']).quantile(0.30), abs(df['bending']).quantile(0.40))\n",
        "  lowmed_diff = (abs(df['sphere_diff']).quantile(0.30), abs(df['sphere_diff']).quantile(0.40))\n",
        "\n",
        "  low_diff = (0, abs(df['sphere_diff']).quantile(0.30))\n",
        "\n",
        "  cond_medhigh_bend = (abs(df['bending']) > medhigh_bend[0]) & (abs(df['bending']) < medhigh_bend[1])\n",
        "  cond_medhigh_diff = (abs(df['sphere_diff']) > medhigh_diff[0]) & (abs(df['sphere_diff']) < medhigh_diff[1])\n",
        "\n",
        "  cond_lowmed_bend = (abs(df['bending']) > lowmed_bend[0]) & (abs(df['bending']) < lowmed_bend[1])\n",
        "  cond_lowmed_diff = (abs(df['sphere_diff']) > lowmed_diff[0]) & (abs(df['sphere_diff']) < lowmed_diff[1])\n",
        "\n",
        "  cond_low_diff = (abs(df['sphere_diff']) > low_diff[0]) & (abs(df['sphere_diff']) < low_diff[1])\n",
        "\n",
        "  num_diff_is2 = (df['num_diff'] == 2)\n",
        "\n",
        "  cond1 = (cond_medhigh_diff & cond_lowmed_bend & num_diff_is2)\n",
        "  cond2 = (cond_lowmed_diff & cond_medhigh_bend & num_diff_is2)\n",
        "  cond3 = (cond_medhigh_diff & cond_medhigh_bend & num_diff_is2)\n",
        "  cond4 = (cond_lowmed_diff & cond_lowmed_bend & num_diff_is2)\n",
        "  cond5 = (cond_lowmed_diff & cond_medhigh_bend)\n",
        "\n",
        "  return cond1, cond2, cond3, cond4, cond5"
      ],
      "metadata": {
        "id": "EilAaWypiWTh"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_rows = nobias_test_df['ill'] == '1'\n",
        "notill_rows = nobias_test_df['ill'] == '0'\n",
        "\n",
        "correct_rows = nobias_test_df['biased_pred'] == nobias_test_df['ill']\n",
        "incorrect_rows = nobias_test_df['biased_pred'] != nobias_test_df['ill']\n",
        "\n",
        "num_diff_is1 = (nobias_test_df['num_diff'] == 1)\n",
        "num_diff_is3 = (nobias_test_df['num_diff'] == 3)\n",
        "\n",
        "cond1, cond2, cond3, cond4, cond5 = get_xai_conds(nobias_test_df)"
      ],
      "metadata": {
        "id": "fxN6gwEAvvA8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = nobias_test_df[cond1 | cond2 | cond3 | cond4 | (cond5 & num_diff_is1) | (cond5 & num_diff_is3)]\n",
        "test_df = test_df.sample(30, random_state=5)\n",
        "\n",
        "correct_rows = test_df['nobias_pred'] == test_df['ill']\n",
        "incorrect_rows = test_df['nobias_pred'] != test_df['ill']\n",
        "\n",
        "ill_rows = test_df['ill'] == '1'\n",
        "notill_rows = test_df['ill'] == '0'\n",
        "\n",
        "num_diff_is1 = (test_df['num_diff'] == 1)\n",
        "num_diff_is3 = (test_df['num_diff'] == 3)\n",
        "\n",
        "cond1, cond2, cond3, cond4, cond5 = get_xai_conds(test_df)"
      ],
      "metadata": {
        "id": "QmQF3JIwZCWb"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "((test_df['biased_pred'] == test_df['ill']).astype(int).mean(),\n",
        "  (test_df['nobias_pred'] == test_df['ill']).astype(int).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFj_Wx-xVvoR",
        "outputId": "d7bf8ef7-008d-46dd-ee66-568837c1ea12"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6333333333333333, 0.6666666666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_cond_stats(cond, title):\n",
        "  print(title)\n",
        "  print('Ill',\n",
        "        abs(test_df[cond & ill_rows]['sphere_diff']).mean(),\n",
        "        abs(test_df[cond & ill_rows]['bending']).mean(),\n",
        "        abs(test_df[cond & ill_rows]['num_diff']).mean(),\n",
        "        abs(test_df[cond & ill_rows]['num_diff']).count()\n",
        "        )\n",
        "  print('Not Ill',\n",
        "        abs(test_df[cond & notill_rows]['sphere_diff']).mean(),\n",
        "        abs(test_df[cond & notill_rows]['bending']).mean(),\n",
        "        abs(test_df[cond & notill_rows]['num_diff']).mean(),\n",
        "        abs(test_df[cond & notill_rows]['num_diff']).count()\n",
        "        )\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "id": "gmR6fr1Iwbq2"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_cond_stats((incorrect_rows & cond1), 'Correct Condition 1 - medhigh sphere diff and medlow bend')\n",
        "print_cond_stats((incorrect_rows & cond2), 'Correct Condition 2 - medhigh sphere diff and medhigh bend')\n",
        "print_cond_stats((incorrect_rows & cond3), 'Correct Condition 3 - medlow sphere diff but medhigh bend')\n",
        "print_cond_stats((incorrect_rows & cond4), 'Correct Condition 4 - low sphere diff but (1,3) changed pieces')\n",
        "print_cond_stats((incorrect_rows & cond5 & (num_diff_is1 | num_diff_is3)), 'Correct Condition 5 - low sphere diff but (1,3) changed pieces')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uITWdATxCUZ",
        "outputId": "fa841dc6-e347-40d6-97ae-05edbebbadb0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Condition 1 - medhigh sphere diff and medlow bend\n",
            "Ill nan nan nan 0\n",
            "Not Ill nan nan nan 0\n",
            "\n",
            "\n",
            "Correct Condition 2 - medhigh sphere diff and medhigh bend\n",
            "Ill nan nan nan 0\n",
            "Not Ill nan nan nan 0\n",
            "\n",
            "\n",
            "Correct Condition 3 - medlow sphere diff but medhigh bend\n",
            "Ill nan nan nan 0\n",
            "Not Ill 0.423738820843456 0.237998045175586 2.0 1\n",
            "\n",
            "\n",
            "Correct Condition 4 - low sphere diff but (1,3) changed pieces\n",
            "Ill nan nan nan 0\n",
            "Not Ill nan nan nan 0\n",
            "\n",
            "\n",
            "Correct Condition 5 - low sphere diff but (1,3) changed pieces\n",
            "Ill nan nan nan 0\n",
            "Not Ill nan nan nan 0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cond 1 - Correct Ill Examples\n",
        "display_images(nobias_test_df[(correct_rows & ill_rows & cond1)], 2, 5, nobias_dir / 'test', 'Correct Ill Cond1 - medhigh sphere diff and medlow bend', random_state=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "qJUswqxqZo9-",
        "outputId": "6acf58e1-b10a-489f-a530-62a691031f4c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 5.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-ca6a5cf77f44>:22: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  test_images = np.array([Image.open(p).convert('RGB') for p in img_dir / df['filename']]) * 1. / 255\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-e670f9f821c3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cond 1 - Correct Ill Examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnobias_test_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_rows\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mill_rows\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcond1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnobias_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Correct Ill Cond1 - medhigh sphere diff and medlow bend'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-ca6a5cf77f44>\u001b[0m in \u001b[0;36mdisplay_images\u001b[0;34m(df, n_rows, n_cols, img_dir, title, random_state)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond1_corr_idxs = [891, 1167] # rand state = 0"
      ],
      "metadata": {
        "id": "uIKPw6aMgTrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cond 1 - Correct Not Ill Examples\n",
        "display_images(nobias_test_df[(correct_rows & notill_rows & cond1)], 2, 5, nobias_dir / 'test', 'Correct Not Ill Cond1 - medhigh sphere diff and medlow bend', random_state=0)"
      ],
      "metadata": {
        "id": "P1drf0l-dBK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond1_corr_idxs = [1520, 357] # rand state = 1"
      ],
      "metadata": {
        "id": "NYcdikhihA9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cond2 - Correct Ill Examples\n",
        "display_images(nobias_test_df[correct_rows & ill_rows & cond2], 2, 5, nobias_dir / 'test', 'Correcct Ill Cond2 - medhigh sphere diff and medhigh bend', random_state=1)"
      ],
      "metadata": {
        "id": "LOSUijWXczCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond2_corr_idxs = [1332, 1533] # rand state = 1"
      ],
      "metadata": {
        "id": "AcP0c7nVhRy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cond2 - Correct Not Ill Examples\n",
        "display_images(nobias_test_df[correct_rows & notill_rows & cond2], 2, 5, nobias_dir / 'test', 'Correct Not Ill Cond2 - medhigh sphere diff and medhigh bend', random_state=1)"
      ],
      "metadata": {
        "id": "qoFN2H8KdD5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond2_corr_idxs = [2085, 512] # rand state = 1"
      ],
      "metadata": {
        "id": "65uUj-wmhgfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cond3 - Correct Ill Examples\n",
        "display_images(nobias_test_df[correct_rows & ill_rows & cond3], 2, 5, nobias_dir / 'test', 'Correct Ill Cond3 - medlow sphere diff but medhigh bend', random_state=0)"
      ],
      "metadata": {
        "id": "JM8UiFBZc0y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond3_corr_idxs = [2765, 1856] # rand state = 0"
      ],
      "metadata": {
        "id": "VteKDYl7TQzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cond3 - Correct Not Ill Examples\n",
        "display_images(nobias_test_df[correct_rows & notill_rows & cond3], 2, 5, nobias_dir / 'test', 'Correct Not Ill Cond3 - lowmed sphere diff but medhigh bend', random_state=32)"
      ],
      "metadata": {
        "id": "_ltsJ_TTdIAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond3_corr_idxs = [2172, 189] # rand state = 32"
      ],
      "metadata": {
        "id": "BoeeHcmgTN6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 4 - Correct Ill Examples\n",
        "display_images(nobias_test_df[correct_rows & ill_rows & cond4 & num_diff_is3], 2, 5, nobias_dir / 'test', 'Correct Ill Cond4 - low sphere diff, medhigh bend, and 3 changed', random_state=1)"
      ],
      "metadata": {
        "id": "l9ufhqpQc18f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond4_corr_idxs = [2531, 1859] # rand state = 32, 1"
      ],
      "metadata": {
        "id": "vb8qxHmcTplw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 4 - Correct Not Ill Examples\n",
        "display_images(nobias_test_df[correct_rows & notill_rows & cond4 & num_diff_is1], 2, 5, nobias_dir / 'test', 'Correct Not Ill Cond4 - low sphere diff and 1 change', random_state=11)"
      ],
      "metadata": {
        "id": "YH1B4spfdKK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond4_corr_idxs = [2829, 2463] # rand state = 11"
      ],
      "metadata": {
        "id": "y7KX5AXAoIJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Incorrect Samples Selection"
      ],
      "metadata": {
        "id": "3iqInKTlvFLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_cond_stats((incorrect_rows & cond1), 'Correct Condition 1 - medhigh sphere diff and medlow bend')\n",
        "print_cond_stats((incorrect_rows & cond2), 'Correct Condition 2 - medhigh sphere diff and medhigh bend')\n",
        "print_cond_stats((incorrect_rows & cond3), 'Correct Condition 3 - medlow sphere diff but medhigh bend')\n",
        "print_cond_stats((incorrect_rows & cond4), 'Correct Condition 4 - low sphere diff but (1,3) changed pieces')"
      ],
      "metadata": {
        "id": "fRz81N8TT2cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 1 - Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & ill_rows & cond1)], 2, 5, nobias_dir / 'test', 'Incorrect Ill Cond1 - medhigh sphere diff and medlow bend', random_state=0)"
      ],
      "metadata": {
        "id": "L85xsimFyepQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond1_inc_idxs = [702] # rand state = 0"
      ],
      "metadata": {
        "id": "9Mo4uX_B2H9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 1 - Not Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & notill_rows & cond1)], 2, 5, nobias_dir / 'test', 'Incorrect Not Ill Cond1 - medhigh sphere diff and medlow bend', random_state=0)\n"
      ],
      "metadata": {
        "id": "hcorYyQvvHUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond1_inc_idxs = [] # no selection for now"
      ],
      "metadata": {
        "id": "7bdpAfHE2YOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 2 - Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & ill_rows & cond2)], 2, 5, nobias_dir / 'test', 'Incorrect Ill Cond2 - medhigh sphere diff and medlow bend', random_state=0)"
      ],
      "metadata": {
        "id": "jdD3hIHR0IaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond2_inc_idxs = [] # no selection"
      ],
      "metadata": {
        "id": "uDPKOUka22kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 2 - Not Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & notill_rows & cond2)], 2, 5, nobias_dir / 'test', 'Incorrect Not Ill Cond2 - medhigh sphere diff and medlow bend', random_state=10)"
      ],
      "metadata": {
        "id": "P-eKm1Hq0lV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond2_inc_idxs = [2625] # rand state = 10"
      ],
      "metadata": {
        "id": "Qmiijex025Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 3 - Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & ill_rows & cond3)], 2, 5, nobias_dir / 'test', 'Incorrect Ill Cond3 - medlow sphere diff and medhigh bend', random_state=0)"
      ],
      "metadata": {
        "id": "YyL0mYT70vs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond3_inc_idxs = [] # no selection"
      ],
      "metadata": {
        "id": "n_b2d_r73nOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 3 - Not Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & notill_rows & cond3)], 2, 5, nobias_dir / 'test', 'Incorrect Not Ill Cond3 - medlow sphere diff and medhigh bend', random_state=5)"
      ],
      "metadata": {
        "id": "P7RU6Jg81m1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond3_inc_idxs = [2876] # rand state = 5"
      ],
      "metadata": {
        "id": "AqWxI3E030CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 4 - Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & ill_rows & cond4 & num_diff_is3)], 2, 5, nobias_dir / 'test', 'Incorrect Ill Cond4 - lows sphere diff and 3 changed', random_state=0)"
      ],
      "metadata": {
        "id": "mZ2nN9LA1wd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ill_cond4_inc_idxs = [] # no selection"
      ],
      "metadata": {
        "id": "yFRr2QjU4zUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition 4 - Not Ill\n",
        "display_images(nobias_test_df[(incorrect_rows & notill_rows & cond4 & num_diff_is1)], 2, 5, nobias_dir / 'test', 'Incorrect Not Ill Cond4 - low sphere diff and 1 changed', random_state=1)"
      ],
      "metadata": {
        "id": "kLAbC-vn15jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notill_cond4_inc_idxs = [2334] # rand state = 0"
      ],
      "metadata": {
        "id": "CYbZeeJ84_-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Selections"
      ],
      "metadata": {
        "id": "QvLVXYuj5OEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_samples = (ill_cond1_corr_idxs + notill_cond1_corr_idxs +\n",
        "                ill_cond2_corr_idxs + notill_cond2_corr_idxs +\n",
        "                ill_cond3_corr_idxs + notill_cond3_corr_idxs +\n",
        "                ill_cond4_corr_idxs + notill_cond4_corr_idxs)\n",
        "inc_samples = (ill_cond1_inc_idxs + notill_cond1_inc_idxs +\n",
        "               ill_cond2_inc_idxs + notill_cond2_inc_idxs +\n",
        "               ill_cond3_inc_idxs + notill_cond3_inc_idxs +\n",
        "               ill_cond4_inc_idxs + notill_cond4_inc_idxs)\n",
        "\n",
        "assert len(set(corr_samples + inc_samples)) == 20, 'selection may contain duplicates'\n",
        "\n",
        "corr_df = nobias_test_df.loc[corr_samples]\n",
        "inc_df = nobias_test_df.loc[inc_samples]\n",
        "\n",
        "final_xai_df = pd.concat([corr_df, inc_df])\n",
        "len(final_xai_df), (final_xai_df['biased_pred'] == final_xai_df['ill']).astype(int).mean()"
      ],
      "metadata": {
        "id": "Hojh9-4N5Smf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(final_xai_df, 4, 5, nobias_dir / 'test', 'Final XAI Dataset')"
      ],
      "metadata": {
        "id": "oHpTKK8b6ofn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xai_images = np.array([Image.open(p).convert('RGB') for p in nobias_dir / 'test' / final_xai_df['filename']]) * 1. / 255"
      ],
      "metadata": {
        "id": "00Q2ihr2-shr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Inputs"
      ],
      "metadata": {
        "id": "vAHKJcagYvkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_blocky(image, id):\n",
        "\n",
        "  figsize = [5, 5]\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
        "\n",
        "  #plot the input image\n",
        "  input_img = resize(image, (256, 256))\n",
        "  ax.imshow(image)\n",
        "  ax.set_title(f'Blocky ID: {id}')\n",
        "  ax.axis('off')"
      ],
      "metadata": {
        "id": "RD59NeNvY0_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = datetime.datetime.today()\n",
        "date_str = today.strftime('%Y-%m-%d')\n",
        "\n",
        "o = output / 'original_input' / 'biased_model' / date_str / 'xai_samples'\n",
        "os.makedirs(o, exist_ok=True)\n",
        "print(f'saving to {o}')\n",
        "\n",
        "for i, ((idx, row), image) in enumerate(zip(final_xai_df.iterrows(), xai_images)):\n",
        "  print(i+1)\n",
        "  show_blocky(image, row[\"id\"])\n",
        "  plt.savefig(o / f'{row[\"id\"]}_true={row[\"ill\"]}_pred={row[\"biased_pred\"]}_input.png')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FgBIdATDY0Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanations of Biased Model"
      ],
      "metadata": {
        "id": "e2fupDHq8Cye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP Explanations"
      ],
      "metadata": {
        "id": "s4mmNWdOp2XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load background images\n",
        "CLASSES = ['Not Ill', 'Ill']\n",
        "\n",
        "n_bck = 250\n",
        "\n",
        "bck_files = nobias_test_df['filename'].sample(n_bck, random_state=5)\n",
        "bck_images = np.array([Image.open(p).convert('RGB') for p in nobias_dir / 'test' / bck_files]) * 1. / 255"
      ],
      "metadata": {
        "id": "KnnZfiZDgJvd"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding input shape to model for shap - https://github.com/shap/shap/issues/1226\n",
        "shap_model_input = tf.keras.layers.Input(shape=(128, 128, 3))\n",
        "shap_model_output = biased_model(shap_model_input)\n",
        "shap_model = tf.keras.models.Model(inputs=shap_model_input, outputs=shap_model_output)\n",
        "\n",
        "# Partition Explaniner\n",
        "# define a masker that is used to mask out partitions of the input image.\n",
        "masker = shap.maskers.Image(\"blur(128,128)\", xai_images[0].shape)\n",
        "explainer = shap.Explainer(biased_model, masker, output_names=CLASSES, max_evals=1000)\n",
        "\n",
        "# Deep Explainer\n",
        "# shap.explainers._deep.deep_tf.op_handlers[\"Relu6\"] = shap.explainers._deep.deep_tf.nonlinearity_1d(0)\n",
        "# shap.explainers._deep.deep_tf.op_handlers[\"FusedBatchNormV3\"] = shap.explainers._deep.deep_tf.linearity_1d(0)\n",
        "# shap.explainers._deep.deep_tf.op_handlers[\"StridedSlice\"] = shap.explainers._deep.deep_tf.passthrough\n",
        "# shap.explainers._deep.deep_tf.op_handlers[\"DepthwiseConv2dNative\"] = shap.explainers._deep.deep_tf.linearity_1d(0)\n",
        "\n",
        "\n",
        "# explainer = shap.DeepExplainer(shap_model, bck_images)"
      ],
      "metadata": {
        "id": "qILvjlEyi6Em"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xai_images.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u4v1P3ra52Q",
        "outputId": "c4778b4a-c09e-4af3-e5ad-608ebdb97a04"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer(xai_images)"
      ],
      "metadata": {
        "id": "tsF37MDSnen3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c01a1450-41d4-4b72-e34b-90f40d6d44b3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Cannot convert a symbolic tf.Tensor (sequential_1_2/dense_1/Softmax:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-682c22304847>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxai_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 def __call__(self, *args, max_evals=500, fixed_context=None, main_effects=False, error_bounds=False, batch_size=\"auto\",\n\u001b[1;32m    114\u001b[0m                              outputs=None, silent=False):\n\u001b[0;32m--> 115\u001b[0;31m                     return super().__call__(\n\u001b[0m\u001b[1;32m    116\u001b[0m                         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    126\u001b[0m                  outputs=None, silent=False):\n\u001b[1;32m    127\u001b[0m         \u001b[0;34m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# if not fixed background or no base value assigned then compute base value for a row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fixed_background\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# the zero index param tells the masked model what the baseline is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mf11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mjoined_masked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_masked_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0m_assert_output_input_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/models/_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mis_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tensor\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    626\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    629\u001b[0m         \u001b[0;34mf\"Cannot convert a symbolic tf.Tensor ({self.name}) to a numpy array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;34mf\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic tf.Tensor (sequential_1_2/dense_1/Softmax:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape data to fit image_plot\n",
        "shap_values_t = np.transpose(shap_values.values, (-1, 0, 1, 2, 3))\n",
        "shap_values_t = list(shap_values_t)"
      ],
      "metadata": {
        "id": "_XkKZByqTZ6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: Ill ones are biased towards red in the training data\n",
        "\n"
      ],
      "metadata": {
        "id": "LCErEAE1MsmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WtWjieF0-5Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_labels = [(CLASSES[int(t)], CLASSES[int(p)]) for t, p in zip(final_xai_df['ill'], final_xai_df['biased_pred'])]\n",
        "shap.image_plot(shap_values_t, xai_images, labels=np.repeat([CLASSES], len(xai_images), axis=0), true_labels=img_labels, show=False)\n",
        "\n",
        "# shap.image_plot(shap_values, true_labels=img_labels, show=False)\n",
        "# plt.savefig('model_nobias_data_nobias.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qHPi-Q6NoFmM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Innvestigate Explanations"
      ],
      "metadata": {
        "id": "2f-P97kBp97i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Y3ero6cVcWdK",
        "outputId": "3647e194-b27c-4493-d585-d98461d9e52c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.25.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nCZBJ4BMcZrb",
        "outputId": "6b5eaf47-0fee-4bec-e756-dca20196e735"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.14.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BbxuJfJYedoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}